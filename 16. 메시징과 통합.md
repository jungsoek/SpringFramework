# 16. 메시징과 통합

## Kafka 연동

- ## Producer, Consumer

  ### 🧩 1. Producer란?

  > **메시지를 생성해서 브로커(중간자)에게 전달하는 역할**
  >  예: 주문 완료 시 메시지 발행 → “OrderCreated”

  ✅ **비동기 처리 시작점**
   ✅ Kafka, RabbitMQ, Redis 등 메시지 브로커에 `send/publish`

  ------

  ### 👂 2. Consumer란?

  > **브로커로부터 메시지를 수신하여 처리하는 역할**
  >  예: 결제 시스템이 주문 메시지를 수신하고 처리 시작

  ✅ **비동기 처리 종착점**
   ✅ 메시지를 받아서 DB 저장, API 호출 등 다양한 작업 수행

  ------

  ### 🔄 3. 전체 메시지 흐름

  ```
  [Producer]
    ↓ publish
  [Broker]  (Kafka, RabbitMQ 등)
    ↓ subscribe
  [Consumer]
  ```

  예시:

  - 주문 서비스 → "OrderCreated" 이벤트 발행 (Producer)
  - 결제 서비스가 해당 이벤트 수신 후 결제 처리 (Consumer)

  ------

  ### ⚙️ 4. Spring Boot 기반 구성 예시

  > 여기선 **Kafka** 기준으로 예시 설명할게
  >  RabbitMQ도 거의 동일한 구조

  ------

  #### ✅ 의존성 추가 (Gradle)

  ```
  implementation("org.springframework.kafka:spring-kafka")
  ```

  ------

  #### ✅ application.yml 설정

  ```
  spring:
    kafka:
      bootstrap-servers: localhost:9092
      consumer:
        group-id: my-service
        auto-offset-reset: earliest
        key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
        value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      producer:
        key-serializer: org.apache.kafka.common.serialization.StringSerializer
        value-serializer: org.apache.kafka.common.serialization.StringSerializer
  ```

  ------

  ### 📤 5. Producer 구현 예시

  ```
  @Service
  @RequiredArgsConstructor
  public class OrderProducer {
  
      private final KafkaTemplate<String, String> kafkaTemplate;
  
      public void publishOrderCreated(Long orderId) {
          String message = String.format("{\"orderId\": %d}", orderId);
          kafkaTemplate.send("order-created-topic", message);
      }
  }
  ```

  ------

  ### 📥 6. Consumer 구현 예시

  ```
  @Component
  public class OrderConsumer {
  
      @KafkaListener(topics = "order-created-topic", groupId = "payment-service")
      public void consume(String message) {
          System.out.println("✅ 주문 생성 이벤트 수신: " + message);
          // 파싱 → 처리 로직 수행
      }
  }
  ```

  ------

  ### 📘 7. 실무 적용 시 고려사항

  | 항목            | Producer 측                 | Consumer 측                      |
  | --------------- | --------------------------- | -------------------------------- |
  | 메시지 중복     | **idempotent하게 처리**     | ✅ 필수                           |
  | 메시지 포맷     | JSON, Avro, Protobuf        | 스키마 통일                      |
  | 실패 처리       | Retry, Dead Letter Topic    | 예외/로그 처리                   |
  | 순서 보장       | Partition 관리              | Kafka: 같은 key → 같은 partition |
  | 비동기 트랜잭션 | DB + 메시지 전송 순서 보장? | Outbox 패턴 필요                 |

  ------

  ### 🧠 8. Producer-Consumer 패턴의 장점

  | 장점        | 설명                           |
  | ----------- | ------------------------------ |
  | 비동기 처리 | 응답 시간 단축, 병렬 처리 가능 |
  | 서비스 분리 | 강한 의존 제거 (느슨한 연결)   |
  | 확장성      | Consumer를 여러 개 확장 가능   |
  | 장애 격리   | 한쪽 다운돼도 메시지는 보존됨  |

  ------

  ### ⚠️ 9. 실무 설계 팁

  | 설계 항목     | 권장 방식                                  |
  | ------------- | ------------------------------------------ |
  | 메시지 스키마 | DTO → JSON 변환 + 명확한 필드 정의         |
  | 로그          | 발행 성공/실패 로깅 필수                   |
  | 재처리        | 실패 시 재시도 또는 DLQ 구성               |
  | 트랜잭션      | Kafka → DB 동시에 다룰 땐 Outbox 패턴 고려 |
  | 테스트        | Embedded Kafka 또는 WireMock 조합 추천     |

  ------

  ### ✅ 마무리 요약표

  | 항목          | 설명                                   |
  | ------------- | -------------------------------------- |
  | Producer      | 메시지 발행자 (`kafkaTemplate.send()`) |
  | Consumer      | 메시지 수신자 (`@KafkaListener`)       |
  | 브로커        | Kafka, RabbitMQ 등 메시지 중계         |
  | 포맷          | JSON/AVRO 권장 (명확한 스키마)         |
  | 실행 흐름     | 발행 → 큐 저장 → 수신/처리             |
  | 트랜잭션 처리 | 메시지/DB 분리 시 Outbox 패턴 검토     |

- ## `@KafkaListener`

  ### 🧩 1. 개념

  > Spring Kafka에서 Kafka 메시지를 수신하고 처리하기 위해 사용하는 어노테이션.

  - 내부적으로 KafkaConsumer를 등록하여 메시지를 **자동 수신**
  - `@KafkaListener`가 선언된 메서드는 **브로커로부터 메시지를 비동기로 처리**함

  ------

  ### 📘 2. 기본 사용법

  ```
  @KafkaListener(topics = "order-created", groupId = "order-consumer")
  public void handleOrder(String message) {
      System.out.println("✅ 주문 메시지 수신: " + message);
  }
  ```

  | 파라미터  | 의미                                                 |
  | --------- | ---------------------------------------------------- |
  | `topics`  | 수신할 Kafka 토픽 이름                               |
  | `groupId` | Consumer Group 이름 (같은 그룹은 파티션을 나눠 가짐) |

  ------

  ### 🔁 3. Kafka 메시지 구조 바인딩

  #### ✅ 문자열 메시지

  ```
  @KafkaListener(topics = "simple-topic")
  public void handle(String message) { ... }
  ```

  ------

  #### ✅ JSON 메시지를 객체로 매핑

  ```
  @KafkaListener(topics = "user-topic", containerFactory = "userKafkaListenerContainerFactory")
  public void handleUser(UserDto dto) {
      System.out.println("👤 사용자 이벤트 수신: " + dto.getName());
  }
  ```

  ```
  @Bean
  public ConcurrentKafkaListenerContainerFactory<String, UserDto> userKafkaListenerContainerFactory() {
      var factory = new ConcurrentKafkaListenerContainerFactory<String, UserDto>();
      factory.setConsumerFactory(new DefaultKafkaConsumerFactory<>(consumerProps(), new StringDeserializer(), new JsonDeserializer<>(UserDto.class)));
      return factory;
  }
  ```

  ------

  ### 🔂 4. Consumer Group 동작 구조

  | 그룹 | 파티션 수 | 인스턴스 수 | 처리 방식                                                    |
  | ---- | --------- | ----------- | ------------------------------------------------------------ |
  | A    | 3         | 3           | 각 인스턴스가 하나의 파티션을 처리                           |
  | A    | 3         | 1           | 하나의 인스턴스가 모든 파티션 처리                           |
  | A    | 3         | 4           | 하나는 대기 상태 (파티션 수보다 인스턴스가 많으면 일부는 idle) |

  ✅ 동일 Group ID를 가진 인스턴스는 **파티션 단위로 분산 처리**됨

  ------

  ### ⚙️ 5. 병렬 처리 (Concurrency)

  ```
  @Bean
  public ConcurrentKafkaListenerContainerFactory<?, ?> kafkaListenerContainerFactory() {
      var factory = new ConcurrentKafkaListenerContainerFactory<>();
      factory.setConcurrency(3);  // 최대 3개 스레드로 병렬 처리
      return factory;
  }
  ```

  > 병렬성은 **파티션 수 이하로만 유효**
  >  Kafka는 각 파티션을 하나의 Consumer가 독점

  ------

  ### 🧨 6. 예외 처리 전략

  #### ✅ try-catch 사용

  ```
  @KafkaListener(topics = "payment")
  public void handle(String message) {
      try {
          // 처리 로직
      } catch (Exception e) {
          log.error("❗ 메시지 처리 실패: {}", message, e);
          // 재처리 큐에 적재 or DLQ 전송
      }
  }
  ```

  ------

  #### ✅ 글로벌 에러 핸들러 설정

  ```
  @Bean
  public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory() {
      var factory = new ConcurrentKafkaListenerContainerFactory<String, String>();
      factory.setErrorHandler((thrownException, data) -> {
          log.error("❗ 예외 발생: {}", data, thrownException);
      });
      return factory;
  }
  ```

  ------

  #### ✅ 재시도 (Retry + Backoff)

  ```
  factory.setRetryTemplate(retryTemplate());
  
  private RetryTemplate retryTemplate() {
      var retry = new RetryTemplate();
      retry.setRetryPolicy(new SimpleRetryPolicy(3));  // 최대 3번 재시도
      retry.setBackOffPolicy(new FixedBackOffPolicy() {{
          setBackOffPeriod(2000); // 2초 간격
      }});
      return retry;
  }
  ```

  ------

  ### 🔐 7. 보안 / 역직렬화 실패 대비

  - 메시지 형식이 예상과 다르면 `DeserializationException` 발생 → 반드시 예외 처리
  - JsonDeserializer 사용 시: `trusted.packages=*` 설정 필요 (또는 명시 지정)

  ```
  spring:
    kafka:
      consumer:
        properties:
          spring.json.trusted.packages: "*"
  ```

  ------

  ### ✅ 마무리 요약표

  | 항목                         | 설명                                                     |
  | ---------------------------- | -------------------------------------------------------- |
  | `@KafkaListener(topics = …)` | 메시지 수신 메서드 등록                                  |
  | `groupId`                    | 컨슈머 그룹 설정 (파티션 분배 기준)                      |
  | `containerFactory`           | 메시지 역직렬화 방식 지정                                |
  | 병렬 처리                    | `concurrency` 수로 컨슈머 동시성 조절                    |
  | 예외 처리                    | try-catch, 글로벌 에러핸들러, 재시도 설정 가능           |
  | DTO 수신                     | `JsonDeserializer`로 객체 매핑 가능                      |
  | 트랜잭션 연계                | `@KafkaListener`는 DB 트랜잭션과 분리됨 → 수동 제어 가능 |

## RabbitMQ 연동

- ## `@RabbitListener`

  ### 🧩 1. `@RabbitListener`란?

  > Spring AMQP에서 **RabbitMQ 큐에 바인딩된 메시지를 비동기로 수신**하는 어노테이션

  ✅ `@KafkaListener`와 유사하지만, AMQP 기반으로 동작
   ✅ Spring Boot + RabbitMQ에서 메시지 기반 소비 처리할 때 사용

  ------

  ### ⚙️ 2. 기본 사용 예시

  ```
  @RabbitListener(queues = "order.queue")
  public void handleOrder(String message) {
      System.out.println("✅ 메시지 수신: " + message);
  }
  ```

  | 파라미터   | 설명                                         |
  | ---------- | -------------------------------------------- |
  | `queues`   | 수신할 큐 이름                               |
  | `bindings` | (선택) Exchange/Queue/Binding 설정 동시 정의 |

  ------

  ### 📘 3. 필수 의존성

  #### ✅ Gradle

  ```
  implementation("org.springframework.boot:spring-boot-starter-amqp")
  ```

  ------

  ### 📂 4. application.yml 설정

  ```
  spring:
    rabbitmq:
      host: localhost
      port: 5672
      username: guest
      password: guest
      listener:
        simple:
          retry:
            enabled: true
            max-attempts: 3
            initial-interval: 1000
  ```

  ------

  ### 📦 5. 메시지 객체 바인딩 (JSON → DTO)

  #### ✅ 메시지 DTO

  ```
  public class OrderMessage {
      private Long orderId;
      private String userEmail;
      // getters/setters
  }
  ```

  #### ✅ 리스너

  ```
  @RabbitListener(queues = "order.queue")
  public void receiveOrder(OrderMessage message) {
      System.out.println("📦 주문 수신: " + message.getOrderId());
  }
  ```

  ➡️ Jackson 메시지 변환 자동 적용됨 (`MappingJackson2MessageConverter`)

  ------

  ### 🔄 6. 큐/익스체인지/바인딩 동시 선언

  ```
  @RabbitListener(
      bindings = @QueueBinding(
          value = @Queue(value = "order.queue", durable = "true"),
          exchange = @Exchange(value = "order.exchange", type = "topic"),
          key = "order.*"
      )
  )
  public void consume(String message) {
      System.out.println("📥 수신: " + message);
  }
  ```

  ✅ 코드 내에서 RabbitMQ 구성 자동 등록 가능

  ------

  ### 🔁 7. 동시성 처리 (Concurrency)

  ```
  spring:
    rabbitmq:
      listener:
        simple:
          concurrency: 3
          max-concurrency: 10
  ```

  > 컨슈머 동시 처리 스레드 수 설정 (파티션 개념 없음)

  ------

  ### 🧨 8. 예외 처리

  #### ✅ 기본: 예외 발생 시 재시도 or DLQ

  - `listener.simple.retry.enabled=true` 설정 시 자동 재시도
  - 재시도 초과 시 메시지는 기본적으로 버려짐 or DLQ 구성 필요

  ------

  #### ✅ try-catch로 수동 처리

  ```
  @RabbitListener(queues = "alert.queue")
  public void consumeWithError(String msg) {
      try {
          // 비즈니스 처리
      } catch (Exception e) {
          log.error("❗ 처리 실패: {}", msg, e);
          // 실패 시 재처리 로직 or 실패 로그 저장
      }
  }
  ```

  ------

  #### ✅ Dead Letter Queue 설정 예시

  ```
  spring:
    rabbitmq:
      listener:
        simple:
          default-requeue-rejected: false
  ```

  그리고 Queue 선언 시:

  ```
  @Bean
  public Queue orderQueue() {
      return QueueBuilder.durable("order.queue")
          .withArgument("x-dead-letter-exchange", "dlx.exchange")
          .withArgument("x-dead-letter-routing-key", "dlx.routing")
          .build();
  }
  ```

  ------

  ### 🧠 9. 실무 설계 팁

  | 항목         | 권장 전략                                                 |
  | ------------ | --------------------------------------------------------- |
  | 메시지 포맷  | JSON + DTO 명확한 구조로 통일                             |
  | 큐 설계      | 도메인 기반 큐 이름 설계 (`order.queue`, `payment.queue`) |
  | 바인딩 설정  | 코드로 함께 정의 or YAML로 선언                           |
  | 예외 처리    | 재시도 → DLQ or 보상 로직 구성                            |
  | 다중 큐 수신 | `@RabbitListener(queues = {"a", "b"})` 가능               |
  | 순서 보장    | RabbitMQ는 큐 단위 순서를 보장하므로 파티션 필요 없음     |

  ------

  ### ✅ 마무리 요약

  | 항목              | 설명                                                  |
  | ----------------- | ----------------------------------------------------- |
  | `@RabbitListener` | 메시지를 큐에서 비동기 수신                           |
  | 큐 지정           | `queues = "..."` 또는 `bindings`로 Exchange 포함 선언 |
  | 메시지 타입       | DTO 자동 매핑 (Jackson)                               |
  | 동시성            | `concurrency`, `max-concurrency` 설정                 |
  | 예외 처리         | 자동 재시도 + DLQ 구성 가능                           |
  | 실무 활용         | 주문, 알림, 이벤트 처리 등 메시지 기반 처리           |

## 메시지 컨버터

### 🧩 1. 메시지 컨버터란?

> **메시지 바이트/텍스트를 객체(자바 POJO)로 직렬화·역직렬화**하는 구성 요소

| 방향              | 동작                                   |
| ----------------- | -------------------------------------- |
| Producer → Broker | 객체 → 바이트/문자열 (직렬화)          |
| Broker → Consumer | 바이트/문자열 → 객체 (역직렬화) ✅ 핵심 |

Spring에서는 메시지 컨버터를 통해
 ✅ JSON → DTO 자동 매핑,
 ✅ DTO → JSON 자동 직렬화가 가능함

------

### 📦 2. 주요 메시지 컨버터 종류

| 컨버터 클래스                           | 설명                                      |
| --------------------------------------- | ----------------------------------------- |
| `StringMessageConverter`                | 문자열 ↔ 문자열 (기본)                    |
| `MappingJackson2MessageConverter`       | JSON ↔ DTO 자동 매핑 (AMQP, WebSocket 등) |
| `JsonMessageConverter` (`spring-kafka`) | Kafka 전용 Jackson 기반 JSON 컨버터       |
| `ByteArrayMessageConverter`             | 바이트 배열 ↔ 객체                        |
| 커스텀 컨버터                           | 사용자 정의 직렬화/역직렬화 방식 구현     |

------

### 📘 3. Spring Kafka에서 메시지 컨버터 등록

#### ✅ JSON → DTO 매핑 예시

```
@Bean
public ConcurrentKafkaListenerContainerFactory<String, MyEvent> kafkaListenerContainerFactory(
        ConsumerFactory<String, MyEvent> consumerFactory) {

    ConcurrentKafkaListenerContainerFactory<String, MyEvent> factory = new ConcurrentKafkaListenerContainerFactory<>();
    factory.setConsumerFactory(consumerFactory);
    factory.setMessageConverter(new StringJsonMessageConverter());  // 핵심!
    return factory;
}
```

➡️ `@KafkaListener`는 JSON 문자열을 DTO로 자동 변환

```
@KafkaListener(topics = "my-topic", containerFactory = "kafkaListenerContainerFactory")
public void handle(MyEvent event) {
    System.out.println("📨 수신: " + event.getName());
}
```

------

### 🐰 4. Spring AMQP(RabbitMQ)에서 메시지 컨버터 설정

```
@Bean
public MessageConverter jsonMessageConverter() {
    return new Jackson2JsonMessageConverter();
}

@Bean
public RabbitTemplate rabbitTemplate(ConnectionFactory cf) {
    RabbitTemplate template = new RabbitTemplate(cf);
    template.setMessageConverter(jsonMessageConverter());
    return template;
}

@Bean
public SimpleRabbitListenerContainerFactory rabbitListenerContainerFactory(ConnectionFactory cf) {
    SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory();
    factory.setConnectionFactory(cf);
    factory.setMessageConverter(jsonMessageConverter());  // 수신 시 컨버터
    return factory;
}
```

➡️ RabbitMQ에서도 `@RabbitListener`에서 DTO 수신 가능

```
@RabbitListener(queues = "order.queue")
public void handle(OrderEvent event) {
    System.out.println("📦 주문 수신: " + event.getOrderId());
}
```

------

### 🔧 5. 커스텀 메시지 컨버터 예시

```
public class CustomUpperCaseConverter implements MessageConverter {

    @Override
    public Message toMessage(Object object, MessageProperties props) throws MessageConversionException {
        String payload = ((String) object).toUpperCase();
        return new Message(payload.getBytes(), props);
    }

    @Override
    public Object fromMessage(Message message) throws MessageConversionException {
        return new String(message.getBody()).toLowerCase();
    }
}
```

➡️ 문자 변환, 암호화, 압축 등도 가능

------

### 🧨 6. 예외 처리

- JSON 파싱 실패 → `DeserializationException`, `MessageConversionException` 발생
- Spring에서는 `ErrorHandler`나 try-catch에서 처리

```
@KafkaListener(topics = "user")
public void handleSafe(String json) {
    try {
        UserDto dto = objectMapper.readValue(json, UserDto.class);
    } catch (JsonProcessingException e) {
        log.error("❗ 메시지 역직렬화 실패", e);
    }
}
```

------

### 🧠 7. 실무 설계 팁

| 항목        | 권장 전략                                           |
| ----------- | --------------------------------------------------- |
| 포맷        | JSON 통일 + Jackson 컨버터 사용                     |
| 메시지 구조 | DTO 설계 시 명확한 필드와 타입 사용                 |
| 에러 처리   | 파싱 실패 시 로그 저장 + DLQ 전송 고려              |
| 통합        | Kafka, RabbitMQ, WebSocket 등 동일 컨버터 방식 유지 |
| 테스트      | Consumer 단위 테스트 시 컨버터까지 포함하여 검증    |

------

### ✅ 마무리 요약

| 항목          | 설명                                              |
| ------------- | ------------------------------------------------- |
| 메시지 컨버터 | 메시지를 DTO로 자동 변환해주는 컴포넌트           |
| Kafka 전용    | `StringJsonMessageConverter`                      |
| AMQP 전용     | `Jackson2JsonMessageConverter`                    |
| 등록 위치     | ListenerFactory 또는 Template에 명시              |
| 실무 활용     | JSON → DTO, DTO → JSON 자동 처리                  |
| 예외 처리     | JSON 파싱 실패 시 `DeserializationException` 발생 |

## 메시지 재처리와 리트라이 전략

### 🧩 1. 왜 메시지 재처리가 중요한가?

> 메시지 소비 중 예외가 발생하면 **그 메시지를 다시 시도하거나**,
>  **실패 메시지를 별도 큐로 분리(DLQ)**해야 시스템이 **안정적이고 견고**해짐

#### ✅ 예:

- DB 일시적 장애 → 메시지 재처리 필요
- 외부 API 타임아웃 → 재시도 후 성공 가능성 있음
- 비정상 메시지 → DLQ로 보내고 로그/모니터링

------

### ⚙️ 2. Kafka vs RabbitMQ 기본 동작 차이

| 항목        | Kafka                                    | RabbitMQ           |
| ----------- | ---------------------------------------- | ------------------ |
| 메시지 저장 | 디스크에 영구 저장                       | 메모리/디스크      |
| 메시지 삭제 | Consumer가 commit 시                     | Consumer가 ack 시  |
| 실패 처리   | 기본 재시도 없음                         | 기본 자동 재전송   |
| DLQ         | 별도 구성 필요                           | 공식 DLX 설정 존재 |
| 재시도 제어 | 수동 구현 (`SeekToCurrent`, retry topic) | 자동 or 수동 가능  |

------

### 📘 3. Spring Kafka: 재시도 + 에러 핸들링

#### ✅ 방식 1: 수동 `try-catch`

```
@KafkaListener(topics = "order")
public void handle(String msg) {
    try {
        // 처리
    } catch (Exception e) {
        log.error("❗ 처리 실패: {}", msg);
        // 재시도 큐로 이동 or 무시
    }
}
```

------

#### ✅ 방식 2: 컨테이너 레벨 리트라이 설정

```
@Bean
public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory() {
    var factory = new ConcurrentKafkaListenerContainerFactory<>();
    factory.setRetryTemplate(retryTemplate());
    factory.setRecoveryCallback(context -> {
        String msg = (String) context.getAttribute("record");
        log.error("❌ 최종 실패 메시지 처리: {}", msg);
        return null;
    });
    return factory;
}
```

```
private RetryTemplate retryTemplate() {
    RetryTemplate retry = new RetryTemplate();

    retry.setRetryPolicy(new SimpleRetryPolicy(3)); // 최대 3회
    retry.setBackOffPolicy(new FixedBackOffPolicy() {{
        setBackOffPeriod(2000); // 2초 간격
    }});

    return retry;
}
```

------

#### ✅ Kafka 고급 전략: Retry Topic + DLQ

- Spring Kafka v2.7+ 부터 `@RetryableTopic`, `@DltHandler` 지원

```
@RetryableTopic(
  attempts = "3",
  backoff = @Backoff(delay = 2000),
  dltTopicSuffix = "-dlt"
)
@KafkaListener(topics = "payment")
public void handle(String msg) {
    ...
}

@DltHandler
public void handleDlt(String dltMessage) {
    log.error("💀 DLQ 도달 메시지: {}", dltMessage);
}
```

➡️ 자동으로 `payment-retry`, `payment-dlt` 토픽이 생성되고 재시도/실패 메시지 분리됨

------

### 🐰 4. Spring RabbitMQ 재시도 전략

#### ✅ 기본 자동 재전송 (ack 안 하면 재전달)

```
@RabbitListener(queues = "order.queue")
public void handle(String msg) {
    throw new RuntimeException("실패!"); // ack 안됨 → 자동 재시도
}
```

#### ✅ 리트라이 구성 (`application.yml`)

```
spring:
  rabbitmq:
    listener:
      simple:
        retry:
          enabled: true
          max-attempts: 3
          initial-interval: 1000
          multiplier: 2.0
```

➡️ 기본적으로 재시도 후 실패 시 message discard

------

#### ✅ DLQ 설정

```
@Bean
public Queue orderQueue() {
    return QueueBuilder.durable("order.queue")
        .withArgument("x-dead-letter-exchange", "dlx.exchange")
        .withArgument("x-dead-letter-routing-key", "dlx.routing")
        .build();
}
```

------

### 🧠 5. 실무 재시도 설계 전략

| 항목          | 설계 기준                                  |
| ------------- | ------------------------------------------ |
| 단순 예외     | 재시도 (ex: DB connection timeout)         |
| 비정상 메시지 | DLQ로 분리 후 수동 확인                    |
| 리트라이 간격 | Fixed or Exponential Backoff               |
| 최대 횟수     | 3~5회, 이후 DLQ로 이동                     |
| DLQ 모니터링  | Slack, email, dashboard 연동               |
| 처리 보장     | Idempotent 처리 필수 (재전송 시 중복 방지) |

------

### ✅ 마무리 요약표

| 항목               | Kafka                                | RabbitMQ                                              |
| ------------------ | ------------------------------------ | ----------------------------------------------------- |
| 기본 재시도        | ❌ (수동)                             | ✅                                                     |
| 리스너 재시도 설정 | RetryTemplate or `@RetryableTopic`   | `spring.rabbitmq.listener.simple.retry.*`             |
| DLQ 구성           | 수동 토픽 구성 or `@DltHandler`      | `x-dead-letter-exchange`, `x-dead-letter-routing-key` |
| Backoff            | Fixed/Exponential                    | YAML에서 설정                                         |
| 메시지 보존        | 디스크 기반 (재시도 주체는 consumer) | 큐 내 보존 후 재전송                                  |

## Dead Letter Queue (DLQ)

### 🧩 1. DLQ란?

> 메시지가 소비 중 **지속적으로 실패하거나 거부되었을 때**,
>  해당 메시지를 **별도의 큐(토픽)로 이동**시켜 격리/보존하는 구조

✅ **재처리 실패 메시지를 분리하고**,
 ✅ 정상 흐름을 유지하며
 ✅ **장애 분석, 보상 처리, 추적**이 가능하게 함

------

### 🔄 2. 동작 흐름 요약

```
Producer → Main Queue/Topic
            ↓ (실패 N회, 예외, nack 등)
         Dead Letter Queue (DLQ)
```

예:

- 3번 재시도 후 실패 → DLQ로 전송
- JSON 파싱 실패 → DLQ 전송 후 알림

------

### ⚙️ 3. Kafka 기반 DLQ 구성

#### ✅ 방법 1: `@RetryableTopic` + `@DltHandler` (Spring Kafka 2.7+)

```
@RetryableTopic(
  attempts = "3",
  backoff = @Backoff(delay = 2000),
  dltTopicSuffix = "-dlt"
)
@KafkaListener(topics = "order")
public void consume(OrderMessage msg) {
    throw new RuntimeException("처리 실패");
}
```

➡️ 자동으로 다음 토픽 생성:

- `order-retry-0`, `order-retry-1` (재시도용)
- `order-dlt` (DLQ)

#### ✅ DLQ 처리

```
@DltHandler
public void handleDlq(OrderMessage msg) {
    log.error("💀 DLQ 메시지 도착: {}", msg);
    // 알림 전송, DB 저장, 수동 보상
}
```

------

#### ✅ 방법 2: 수동 DLQ Producer 전송

```
@KafkaListener(topics = "order")
public void handle(String msg) {
    try {
        ...
    } catch (Exception ex) {
        kafkaTemplate.send("order-dlq", msg); // DLQ 수동 전송
    }
}
```

------

### 🐰 4. RabbitMQ 기반 DLQ 구성

#### ✅ Queue 설정: `x-dead-letter-exchange`

```
@Bean
public Queue mainQueue() {
    return QueueBuilder.durable("order.queue")
        .withArgument("x-dead-letter-exchange", "dlx.exchange")
        .withArgument("x-dead-letter-routing-key", "order.dlq")
        .build();
}

@Bean
public Queue deadLetterQueue() {
    return QueueBuilder.durable("order.dlq").build();
}

@Bean
public DirectExchange dlxExchange() {
    return new DirectExchange("dlx.exchange");
}

@Bean
public Binding dlqBinding() {
    return BindingBuilder.bind(deadLetterQueue())
        .to(dlxExchange()).with("order.dlq");
}
```

➡️ 메시지 소비 중 예외 발생 시 DLQ로 자동 전송됨

------

### 📘 5. Spring Rabbit에서 DLQ 자동 전송 조건

| 조건       | 설명                                  |
| ---------- | ------------------------------------- |
| 예외 발생  | `@RabbitListener`에서 Exception throw |
| Ack 실패   | 수동 ack 실패 시                      |
| TTL 만료   | 메시지 지연 후 만료되면 DLQ로 이동    |
| Queue full | 큐 초과 시 정책 설정에 따라 DLQ 전송  |

------

### 🔁 6. DLQ 재처리 전략

| 전략            | 설명                                |
| --------------- | ----------------------------------- |
| 수동 재처리     | DLQ 메시지를 읽고, 원래 큐로 재전송 |
| 대시보드 + 승인 | 관리자가 승인 시 재전송 or Drop     |
| 자동 재처리     | 일정 시간 후 polling하여 재시도     |

```
@Scheduled(fixedDelay = 60000)
public void reconsumeDlq() {
    List<Message> dlqMsgs = dlqRepo.fetch();
    for (Message msg : dlqMsgs) {
        mainProducer.send(msg.getPayload());  // 원래 큐로 재전송
    }
}
```

------

### 📊 7. DLQ 모니터링 구성

| 도구                 | 설명                                 |
| -------------------- | ------------------------------------ |
| Spring Boot Actuator | Kafka, RabbitMQ 상태 확인 가능       |
| Prometheus + Grafana | DLQ 메시지 수, 에러 수 대시보드      |
| Log Alert            | DLQ 수신 로그 Slack 연동             |
| Dead Letter Audit    | DB 테이블에 DLQ 메시지 저장 + 트래킹 |

------

### 🧠 8. 실무 설계 팁

| 항목          | 권장 전략                                    |
| ------------- | -------------------------------------------- |
| DLQ 이름 규칙 | `order.dlq`, `user.dlt`, `topic-name-dlq`    |
| 메시지 포맷   | DTO + 실패 이유 포함 (`reason`, `timestamp`) |
| DLQ 보존 기간 | TTL 설정 + 수동 or 자동 정리                 |
| 알림 시스템   | DLQ 도착 시 Slack, Email, JIRA 연동          |
| 보상 처리     | 관리자 승인 + 재처리 API or Batch 스케줄러   |

------

### ✅ 마무리 요약

| 항목      | 설명                                                  |
| --------- | ----------------------------------------------------- |
| DLQ 목적  | 실패 메시지 격리, 정상 흐름 보호, 사후 분석           |
| Kafka     | `@RetryableTopic` + `@DltHandler`, or 수동 DLQ        |
| RabbitMQ  | `x-dead-letter-exchange`, `x-dead-letter-routing-key` |
| 재처리    | 수동 or 자동 재전송 구조 구성                         |
| 모니터링  | 대시보드, 로그, 알림 연계 필수                        |
| 실무 기준 | DLQ는 “실패를 기록하고 다시 성공할 기회를 주는 구조”  |

## Spring Integration 기본 구조

### 🧩 1. Spring Integration이란?

> 다양한 시스템, 프로토콜, 메시징을 Spring 기반으로 **모듈화된 방식으로 통합**하기 위한 프레임워크.

✅ EIP(Enterprise Integration Patterns) 구현
 ✅ MQ, HTTP, JMS, TCP/UDP, FTP, Mail, File 등 다양한 **입출력 연동** 가능
 ✅ 메시지를 중심으로 **비동기/동기 이벤트 흐름을 설계**

------

### 🎯 2. 왜 사용하는가?

- 시스템 간 **비동기 데이터 흐름**을 구성
- Kafka, RabbitMQ, File, REST API, DB 등 다양한 채널을 통합
- **오케스트레이션 / 파이프라인 처리 / 메시지 라우팅 / 변환** 등 구현
- 이벤트 드리븐 아키텍처를 **코드가 아닌 DSL 구성으로 설계**

------

### 📦 3. Spring Integration 핵심 개념 구조

```
[Inbound Adapter] → [Message Channel] → [Message Handler or Router] → [Outbound Adapter]
```

| 구성 요소             | 설명                                                         |
| --------------------- | ------------------------------------------------------------ |
| **Message**           | 실제 데이터 (`payload`) + 메타 정보 (`headers`)              |
| **Channel**           | 메시지를 전달하는 통로 (`DirectChannel`, `QueueChannel`, `PublishSubscribeChannel`) |
| **Gateway**           | 외부 요청을 시스템 메시지로 변환                             |
| **Adapter**           | 외부 시스템과 연동 (e.g. Kafka, Mail, FTP)                   |
| **Transformer**       | 메시지를 다른 형식으로 변환                                  |
| **Router**            | 조건에 따라 메시지 흐름을 분기                               |
| **Filter**            | 메시지를 필터링 (drop or pass)                               |
| **Service Activator** | 실제 비즈니스 로직 처리기                                    |
| **Bridge**            | 채널 간 메시지를 연결                                        |

------

### 🔗 4. 전체 흐름 예시 (예: REST → Kafka)

```
HTTP → Inbound Gateway → Channel → Transformer → Kafka Outbound Adapter
```

1. 클라이언트 요청 (`/send`)
2. 메시지 생성 → Channel로 전달
3. Transformer가 메시지 가공
4. Kafka로 전송됨

------

### 🛠️ 5. 기본 설정 예시 (Java DSL)

```
@Configuration
@EnableIntegration
public class IntegrationFlowConfig {

    @Bean
    public IntegrationFlow sampleFlow() {
        return IntegrationFlows.from(Http.inboundGateway("/send"))
            .transform(String.class, String::toUpperCase) // 대문자 변환
            .handle(m -> System.out.println("🔔 수신 메시지: " + m.getPayload()))
            .get();
    }
}
```

➡️ `/send`로 POST하면 메시지가 대문자로 변환되어 출력됨

------

### 📘 6. 주요 컴포넌트 정리

#### ✅ Channel (메시지 통로)

```
@Bean
public MessageChannel inputChannel() {
    return new DirectChannel();
}
```

- `DirectChannel`: 싱글 소비자, 동기 처리
- `QueueChannel`: 비동기 대기 가능
- `PublishSubscribeChannel`: 브로드캐스트

------

#### ✅ Transformer (메시지 변환)

```
.transform(String.class, msg -> "Hello, " + msg)
```

------

#### ✅ Router (조건 분기)

```
.route(String.class, msg -> msg.contains("VIP") ? "vipChannel" : "normalChannel")
```

------

#### ✅ Service Activator (핸들러)

```
.handle(MyMessageHandler.class, "process")
```

또는 람다로 처리

```
.handle(msg -> processMessage(msg.getPayload()))
```

------

### 💡 7. 실전 사용 예시

| 시나리오                | 구성                                                  |
| ----------------------- | ----------------------------------------------------- |
| 주문 수신 후 Kafka 전송 | `Http → Transformer → Kafka.outboundChannelAdapter()` |
| DB → Polling → MQ       | `JdbcInboundAdapter → Channel → RabbitAdapter`        |
| 파일 업로드 처리        | `FileInboundAdapter → Filter → ServiceActivator`      |
| 이메일 수신 자동 처리   | `MailInboundAdapter → Transformer → SlackNotifier`    |

------

### ✅ 마무리 요약표

| 구성 요소         | 역할                                                |
| ----------------- | --------------------------------------------------- |
| Message           | payload + headers                                   |
| Channel           | 메시지 경로 (`Direct`, `Queue`, `PublishSubscribe`) |
| Gateway           | 외부 호출 ↔ 메시지 변환                             |
| Adapter           | 외부 시스템 연동 (Kafka, FTP, Mail 등)              |
| Transformer       | 메시지 형식 변환                                    |
| Filter            | 메시지 통과 여부 결정                               |
| Router            | 조건에 따라 분기 처리                               |
| Service Activator | 실제 로직 수행 위치                                 |

